name: CI

on:
  push:
    branches: [master, develop]
  pull_request:
    branches: [master]
  schedule:
    # Run weekly on Mondays to catch upstream changes
    - cron: '0 0 * * 1'

env:
  FORCE_COLOR: 1

jobs:
  # Main test matrix across OS and Python versions
  test:
    runs-on: ${{ matrix.os }}
    strategy:
      fail-fast: false
      matrix:
        os: [ubuntu-latest, macos-latest, windows-latest]
        python-version: ["3.11", "3.12", "3.13"]
        exclude:
          # macOS has issues with signal-based sampling
          - os: macos-latest
            python-version: "3.11"
          - os: macos-latest
            python-version: "3.12"

    # Only experimental builds can fail
    continue-on-error: ${{ matrix.experimental || false }}

    steps:
      - uses: actions/checkout@v4

      - name: Set up Python ${{ matrix.python-version }}
        uses: actions/setup-python@v5
        with:
          python-version: ${{ matrix.python-version }}
          allow-prereleases: true

      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip setuptools wheel
          pip install -e ".[dev]"

      - name: Run tests with coverage
        run: |
          python -m pytest tests/test_profiler.py tests/test_output.py tests/test_coverage.py -v --tb=short --cov=spprof --cov-report=xml --cov-report=term-missing
        timeout-minutes: 5

      - name: Upload coverage to Codecov
        if: matrix.os == 'ubuntu-latest' && matrix.python-version == '3.12'
        uses: codecov/codecov-action@v4
        with:
          files: coverage.xml
          fail_ci_if_error: false
          verbose: true
        env:
          CODECOV_TOKEN: ${{ secrets.CODECOV_TOKEN }}

  # Test on Python 3.14-dev (experimental)
  test-dev:
    runs-on: ubuntu-latest
    continue-on-error: true
    steps:
      - uses: actions/checkout@v4

      - name: Set up Python 3.14-dev
        uses: actions/setup-python@v5
        with:
          python-version: "3.14-dev"
          allow-prereleases: true

      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip setuptools wheel
          pip install -e ".[dev]"

      - name: Run tests
        run: |
          python -m pytest tests/test_profiler.py -v --tb=short
        timeout-minutes: 5

  # macOS tests (experimental - signal handling is different)
  test-macos:
    runs-on: macos-latest
    continue-on-error: true
    strategy:
      matrix:
        python-version: ["3.12", "3.13"]
    steps:
      - uses: actions/checkout@v4

      - name: Set up Python ${{ matrix.python-version }}
        uses: actions/setup-python@v5
        with:
          python-version: ${{ matrix.python-version }}

      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip setuptools wheel
          pip install -e ".[dev]"

      - name: Run basic tests
        run: |
          python -m pytest tests/test_profiler.py -v --tb=short -k "not cpu_bound"
        timeout-minutes: 5

  # Python 3.13 free-threaded build (experimental)
  free-threaded:
    runs-on: ubuntu-latest
    continue-on-error: true
    steps:
      - uses: actions/checkout@v4

      - name: Set up Python 3.13 free-threaded
        uses: actions/setup-python@v5
        with:
          python-version: "3.13t"
        continue-on-error: true

      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip setuptools wheel
          pip install -e ".[dev]"
        continue-on-error: true

      - name: Run tests
        run: |
          python -m pytest tests/test_profiler.py -v --tb=short
        continue-on-error: true
        timeout-minutes: 5

  # Lint, format, and type checking
  lint:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v4

      - name: Set up Python 3.12
        uses: actions/setup-python@v5
        with:
          python-version: "3.12"

      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install ruff mypy

      - name: Check formatting (ruff format)
        run: |
          ruff format --check src/ tests/ benchmarks/ examples/

      - name: Lint (ruff check)
        run: |
          ruff check src/ tests/ benchmarks/ examples/

      - name: Type check (mypy)
        run: |
          mypy src/spprof --ignore-missing-imports

  # Build wheels for all platforms
  build:
    runs-on: ${{ matrix.os }}
    strategy:
      fail-fast: false
      matrix:
        os: [ubuntu-latest, macos-latest, windows-latest]
        python-version: ["3.11", "3.12", "3.13"]

    steps:
      - uses: actions/checkout@v4

      - name: Set up Python ${{ matrix.python-version }}
        uses: actions/setup-python@v5
        with:
          python-version: ${{ matrix.python-version }}

      - name: Install build tools
        run: |
          python -m pip install --upgrade pip setuptools wheel
          pip install build

      - name: Build wheel
        run: |
          python -m build --wheel

      - name: Upload wheel
        uses: actions/upload-artifact@v4
        with:
          name: wheel-${{ matrix.os }}-py${{ matrix.python-version }}
          path: dist/*.whl

  # Benchmarks (experimental)
  benchmark:
    runs-on: ubuntu-latest
    continue-on-error: true
    steps:
      - uses: actions/checkout@v4

      - name: Set up Python 3.12
        uses: actions/setup-python@v5
        with:
          python-version: "3.12"

      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip setuptools wheel
          pip install -e ".[dev]"

      - name: Run benchmarks
        run: |
          python benchmarks/overhead.py --intervals 10 100 --json > benchmark_results.json
        timeout-minutes: 5

      - name: Upload benchmark results
        uses: actions/upload-artifact@v4
        with:
          name: benchmark-results
          path: benchmark_results.json
